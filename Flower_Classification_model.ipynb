{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Flower_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nunival/flower_classifier/blob/main/Flower_Classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Flower classification with TensorFlow Lite Model Maker with TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m86-Nh4pMHqY"
      },
      "source": [
        "Model Maker library simplifies the process of adapting and converting a TensorFlow neural-network model to particular input data when deploying this model for on-device ML applications.\n",
        "\n",
        "I've taken some sample code from Tensorflow to use Model Maker with my data to train a flower classification CV model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cv3K3oaksJv"
      },
      "source": [
        "!pip install tflite-model-maker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx1HGRoFQ54j"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.image_classifier import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiZZ5DHXotaW"
      },
      "source": [
        "### Get the data path\n",
        "\n",
        "I'm directly grabbing the data from the University of Oxford. \n",
        "\n",
        "<img src=\"https://www.robots.ox.ac.uk/~vgg/data/flowers/17/categories.jpg\" alt=\"Upload File\" width=\"800\" hspace=\"100\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6QRy0oP-nUw"
      },
      "source": [
        "!mkdir \"/content/input\"\n",
        "!mkdir \"/content/train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3jz5x0JoskPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7eb2884-5d81-4e19-d667-491b5c2b5d7c"
      },
      "source": [
        "image_path = tf.keras.utils.get_file(\n",
        "      '/content/input/flower_photos',\n",
        "      'https://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz',\n",
        "      untar=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz\n",
            "60276736/60270631 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtAe2RJ0F0qT"
      },
      "source": [
        "import os, sys, tarfile\n",
        "\n",
        "def extract(tar_url, extract_path='.'):\n",
        "    print(tar_url)\n",
        "    tar = tarfile.open(tar_url, 'r')\n",
        "    for item in tar:\n",
        "        tar.extract(item, extract_path)\n",
        "        if item.name.find(\".tgz\") != -1 or item.name.find(\".tar\") != -1:\n",
        "            extract(item.name, \"./\" + item.name[:item.name.rfind('/')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at2A09aEGX52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b86936-a618-48e3-f7cc-e19a17f0583d"
      },
      "source": [
        "extract(\"/content/input/flower_photos.tar.gz\", \"/content/input\" )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/input/flower_photos.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FoePmAWdef2"
      },
      "source": [
        "The data comes in with no organization. It has jpg with labels of jpg_0001 to jpg_1360. The code below organizes the images into folders with the label name for each folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIouq3qNDHqs",
        "outputId": "5db4be41-b7d3-45cd-e826-669e320392db"
      },
      "source": [
        "# organize imports\n",
        "import os\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "# print start time\n",
        "print(\"[INFO] program started on - \" + str(datetime.datetime.now))\n",
        "\n",
        "# get the input and output path\n",
        "input_path  = \"/content/input/jpg\"\n",
        "output_path = \"/content/train\"\n",
        "\n",
        "# get the class label limit\n",
        "class_limit = 17\n",
        "\n",
        "# take all the images from the dataset\n",
        "image_paths = glob.glob(input_path + \"/*.jpg\")\n",
        "\n",
        "# variables to keep track\n",
        "label = 0\n",
        "i = 0\n",
        "j = 80\n",
        "\n",
        "# flower17 class names\n",
        "class_names = [\"daffodil\", \"snowdrop\", \"lilyvalley\", \"bluebell\", \"crocus\",\n",
        "\t\t\t   \"iris\", \"tigerlily\", \"tulip\", \"fritillary\", \"sunflower\", \n",
        "\t\t\t   \"daisy\", \"coltsfoot\", \"dandelion\", \"cowslip\", \"buttercup\",\n",
        "\t\t\t   \"windflower\", \"pansy\"]\n",
        "\n",
        "# change the current working directory\n",
        "os.chdir(output_path)\n",
        "\n",
        "# loop over the class labels\n",
        "for x in range(1, class_limit+1):\n",
        "\t# create a folder for that class\n",
        "  os.system(\"mkdir \" + class_names[label])\n",
        "\t# get the current path\n",
        "  cur_path = output_path + \"/\" + class_names[label] + \"/\"\n",
        "\t# loop over the images in the dataset\n",
        "  for n in range(i,j):\n",
        "    os.system(\"cp \" + input_path + \"/image_\"+ f\"{n+1:04d}\" +\".jpg\" + \" \" + cur_path + \"/image_\"+ f\"{n+1:04d}\" +\".jpg\")\n",
        "\n",
        "  i += 80\n",
        "  j += 80\n",
        "  label += 1\n",
        "\n",
        "# print end time\n",
        "print(\"[INFO] program ended on - \" + str(datetime.datetime.now))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] program started on - <built-in method now of type object at 0x55cb7aa48700>\n",
            "[INFO] program ended on - <built-in method now of type object at 0x55cb7aa48700>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VDriAdsowu"
      },
      "source": [
        "## Model\n",
        "Using Model Maker to build my classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lANoNS_gtdH1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77058282-852a-48af-9340-5f1b0df07124"
      },
      "source": [
        "data = DataLoader.from_folder(\"/content/train\")\n",
        "train_data, test_data = data.split(0.8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Load image with size: 1360, num_label: 17, labels: bluebell, buttercup, coltsfoot, cowslip, crocus, daffodil, daisy, dandelion, fritillary, iris, lilyvalley, pansy, snowdrop, sunflower, tigerlily, tulip, windflower.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRXMZbrwtyRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cda615-565e-43b5-e3db-5b54f4a1f39b"
      },
      "source": [
        "model = image_classifier.create(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n",
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hub_keras_layer_v1v2 (HubKer (None, 1280)              3413024   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 17)                21777     \n",
            "=================================================================\n",
            "Total params: 3,434,801\n",
            "Trainable params: 21,777\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "34/34 [==============================] - 41s 279ms/step - loss: 2.3285 - accuracy: 0.3640\n",
            "Epoch 2/5\n",
            "34/34 [==============================] - 10s 285ms/step - loss: 1.2307 - accuracy: 0.8548\n",
            "Epoch 3/5\n",
            "34/34 [==============================] - 10s 283ms/step - loss: 0.9889 - accuracy: 0.9154\n",
            "Epoch 4/5\n",
            "34/34 [==============================] - 10s 284ms/step - loss: 0.9133 - accuracy: 0.9320\n",
            "Epoch 5/5\n",
            "34/34 [==============================] - 10s 282ms/step - loss: 0.8763 - accuracy: 0.9357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxU2fDr-t2Ya"
      },
      "source": [
        "Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQr02VxJt6Cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ee3d2d-edff-4dbb-ea3f-8f9c9956fe8f"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 4s 302ms/step - loss: 0.9430 - accuracy: 0.9081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVZw9zU8t84y"
      },
      "source": [
        "Export to TensorFlow Lite model.\n",
        "\n",
        "Using this model in my app"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb-eIzfluCoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10d3b34c-d2a5-4ed2-a009-f8dc5b9d6154"
      },
      "source": [
        "model.export(export_dir='.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3thwk81_/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3thwk81_/assets\n",
            "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpj_erpjku/labels.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmpj_erpjku/labels.txt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model.tflite\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model.tflite\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CMSWRCUVG-m-",
        "outputId": "59b55187-c082-4164-9cea-5b556fc824e3"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.tflite') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_97e42b14-5df0-4332-9e5d-ea09e9232e02\", \"model.tflite\", 4029065)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}